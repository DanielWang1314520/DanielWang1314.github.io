#                    《人工智能》课程

#                             实验报告



​                                    ![](https://s2.loli.net/2022/06/30/qrbMW1zJNuDOIAP.jpg)  

​                                                            

​    



#                     **网络与信息安全学院**

 

 

#               **班  级：** 

#               **姓  名：**

#               **学  号：** 

#                 **提交时间：** 2022/6/25 

 

 

## **基于神经网络的MNIST手写数字识别**



**一、实验目的**

w  掌握运用神经网络模型解决有监督学习问题

w  掌握机器学习中常用的模型训练测试方法

w  了解不同训练方法的选择对测试结果的影响

**二、****实验内容**

**MNIST****数据集**

本实验采用的数据集MNIST是一个手写数字图片数据集，共包含图像和对应的标签。数据集中所有图片都是28x28像素大小，且所有的图像都经过了适当的处理使得数字位于图片的中心位置。MNIST数据集使用二进制方式存储。图片数据中每个图片为一个长度为784（28x28x1，即长宽28像素的单通道灰度图）的一维向量，而标签数据中每个标签均为长度为10的一维向量。

**分层采样方法**

分层采样（或分层抽样，也叫类型抽样）方法，是将总体样本分成多个类别，再分别在每个类别中进行采样的方法。通过划分类别，采样出的样本的类型分布和总体样本相似，并且更具有代表性。在本实验中，MNIST数据集为手写数字集，有0~9共10种数字，进行分层采样时先将数据集按数字分为10类，再按同样的方式分别进行采样。

**神经网络模型评估方法**

​    通常，我们可以通过实验测试来对神经网络模型的误差进行评估。为此，需要使用一个测试集来测试模型对新样本的判别能力，然后以此测试集上的测试误差作为误差的近似值。两种常见的划分训练集和测试集的方法：

​    留出法（hold-out）直接将数据集按比例划分为两个互斥的集合。划分时为尽可能保持数据分布的一致性，可以采用分层采样（stratified sampling）的方式，使得训练集和测试集中的类别比例尽可能相似。需要注意的是，测试集在整个数据集上的分布如果不够均匀还可能引入额外的偏差，所以单次使用留出法得到的估计结果往往不够稳定可靠。在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。

​    k折交叉验证法（k-fold cross validation）先将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即也采用分层采样（stratified sampling）的方法。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练集和测试集，从而可以进行k次训练和测试。最终返回的是这k个测试结果的均值。显然，k折交叉验证法的评估结果的稳定性和保真性在很大程度上取决于k的取值。k最常用的取值是10，此外常用的取值还有5、20等。

三、实验方法设计

​    介绍实验中程序的总体设计方案、关键步骤的编程方法及思路，主要包括:

1） 模型构建的程序设计（伪代码或源代码截图）及说明解释 

![人工智能实验](https://s2.loli.net/2022/06/30/WHi7zBohXSglEJL.png)

构建上图所示神经网络为模型，该神经网络包含4个隐藏层，4个隐藏层中的神经元数量分别为200、100、60、30, 层与层之间使用的激活函数为relu激活函，设置激活函数的目的是保证结果输出的非线性化，RELU激活函数需要大于一个阈值，才会有输出，和人的神经元结构很像。由最后一个隐藏层到输出层的激活函数为softmax function，，呈逐层递减的趋势

 

**代码：**

\# 构建和训练模型

```python
def train_and_test(images_train, labels_train, images_test, labels_test, images_validation, labels_validation):

  X = tf.placeholder(tf.float32, [None, 784])

  y_ = tf.placeholder(tf.float32, [None, 10])

  L = 200

  M = 100

  N = 60

  O = 30

  W1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1)) # 784 = 28 * 28

  B1 = tf.Variable(tf.ones([L]) / 10)

 

  W2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))

  B2 = tf.Variable(tf.ones([M]) / 10)

 

  W3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))

  B3 = tf.Variable(tf.ones([N]) / 10)

 

  W4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))

  B4 = tf.Variable(tf.ones([O]) / 10)

 

  W5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))

 

  B5 = tf.Variable(tf.zeros([10]))

  XX = tf.reshape(X, [-1, 784])

 

  Y1 = tf.nn.relu(tf.matmul(XX, W1) + B1)

  Y2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)

  Y3 = tf.nn.relu(tf.matmul(Y2, W3) + B3)

  Y4 = tf.nn.relu(tf.matmul(Y3, W4) + B4)

  Ylogits = tf.matmul(Y4, W5) + B5

  Y = tf.nn.softmax(Ylogits)
```

2） 模型迭代训练的程序设计（伪代码或源代码截图）及说明解释 

损失函数即交叉熵损失函数：

![img](https://s2.loli.net/2022/06/30/1Iziw4aljmbVCvK.jpg)

设置学习率：0.1

![img](https://s2.loli.net/2022/06/30/GSFnWaclYNyievr.jpg)

设置优化器，梯度下降，使损失函数最小：

![img](https://s2.loli.net/2022/06/30/7cWSul3vgjRw8ma.jpg)

然后进行迭代循环：

![img](https://s2.loli.net/2022/06/30/eS5BVaivhbPKOMu.jpg)



3） 模型训练过程中周期性测试的程序设计（伪代码或源代码截图）及说明解释（周期性测试指的是每训练n个step就对模型进行一次测试，得到准确率和loss值）

设置i=5000，即设置迭代次数为5000，且每隔100次迭代输出一次损失函数值和模型在验证集上的准确率。

代码如上图所示：

![img](https://s2.loli.net/2022/06/30/fZmx9o1ndHcLkp6.jpg)

4） 分层采样的程序设计（伪代码或源代码截图）及说明解释 

使用sklearn库model_selection模块中的train_test_split模块

![img](https://s2.loli.net/2022/06/30/XuC4Blf1md73x2V.jpg)

并使用留出法对数据集进行划分，划分之后再调用前面已经写好的train_and_test函数进行模型训练以及测试。

“留出法”直接将数据集划分为两个互斥的集合，其中一个作为训练集，另外一个作为测试集，在训练集上训练模型，使用测试集来评估测试误差，作为对泛化误差的估计。

![img](https://s2.loli.net/2022/06/30/PeZovKs7b29LAim.jpg)

5） k折交叉验证法的程序cc设计（伪代码或源代码截图）及说明解释 

k折交叉验证法（k-fold cross validation）先将数据集划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，即也采用分层采样（stratified sampling）的方法。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练集和测试集，从而可以进行k次训练和测试。最终返回的是这k个测试结果的均值。

具体操作为：

1、 将全部训练集 S分成 k个不相交的子集，假设 S中的训练样例个数为 m，那么每一个子 集有 m/k 个训练样例，，相应的子集称作 {s1,s2,…,sk}。

2、每次从分好的子集中里面，拿出一个作为测试集，其它k-1个作为训练集

3、根据训练训练出模型或者假设函数。

4、 把这个模型放到测试集上，得到分类率。

5、计算k次求得的分类率的平均值，作为该模型或者假设函数的真实分类率。

模型图为：

![IMG_256](https://s2.loli.net/2022/06/30/4AgmbCzWthL9UXk.png)

 

代码实现：

![img](https://s2.loli.net/2022/06/30/57FuPidYGAyhWXQ.jpg)

 

**四、实验结果展示**

展示程序界面设计、运行结果及相关分析等，主要包括：

1）模型在验证集下的准确率（输出结果并截图）

![image-20220630104230347](https://s2.loli.net/2022/06/30/KFg1yJQqBLnW7f5.png)

![image-20220630104243394](https://s2.loli.net/2022/06/30/URKNuqradLeslcv.png)

![image-20220630104251250](https://s2.loli.net/2022/06/30/oLc5sdkXJO2zfia.png)

 

![N~O76~_P1RO@$OA)XYHPB_F](https://s2.loli.net/2022/06/30/vC7YM4Wc8rLZIVg.jpg)

 

由上图看出，叠代3700次的时候，已经满足了准确率达到97%的需求。

 

2）不同模型参数（隐藏层数、隐藏层节点数）对准确率的影响和分析 （10分）

不同隐藏层数对于准确率的影响：

| 隐藏层数量               | 0      | 1      | 2      | 3      | 4      |
| ------------------------ | ------ | ------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.8978 | 0.9316 | 0.9424 | 0.9446 | 0.9514 |

隐藏层数越多，模型准确率越高。猜测隐藏层数越多，可挖掘到的数据中的特征就越全面，进而使准确率越高。

不同隐藏层节点数对准确率的影响，为了方便测试，这里选用仅有一层隐藏层的神经网络模型：

| 隐藏层节点数             | 100    | 200    | 300    | 400    | 500    |
| ------------------------ | ------ | ------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.9306 | 0.9316 | 0.9378 | 0.9386 | 0.9496 |

不难看出，隐藏层节点数越多，模型准确率越高。同理，隐藏层的节点越多，可挖掘到的数据中的特征就越全面，进而使准确率越高。

 

3）不同训练参数（batch size、epoch num、学习率）对准确率的影响和分析 （10分）

Batch size对准确率的影响：

| Batch size               | 50     | 100    | 150    |
| ------------------------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.9394 | 0.9514 | 0.9484 |

这里无法从上述几个数据中直接看出batch size对准确率的影响，于是我上网查找相关资料显示：batch-size：顾名思义就是批次大小，也就是一次训练选取的样本个数。一般来说，在合理的范围之内，越大的 batch size 使下降方向越准确，震荡越小；batch size 如果过大，则可能会出现局部最优的情况；小的 batch size 引入的随机性更大，难以达到收敛，极少数情况下可能会效果变好。

对于本实验来说，100为最优的batch size值。

Epoch num对准确率的影响：

| Epoch num                | 15     | 25     | 35     |
| ------------------------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.9474 | 0.9514 | 0.9488 |

也不能直观地看出epoch num对于模型准确率的影响。1个epoch指用训练集中的全部样本训练一次，此时相当于batchsize 等于训练集的样本数。对于不同的数据集，答案是不一样的。但是数据的多样性会影响合适的epoch的数量。

对于本实验来说，25为最优的epoch num值。

学习率对准确率的影响：

| 学习率                   | 0.01   | 0.05   | 0.1    |
| ------------------------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.8478 | 0.9324 | 0.9514 |

学习率越高，则初期训练过程越快，模型的准确率越高。但该结果仅仅是由于我们选取的准确率测试节点为1000次迭代之后，或是我没有对更高的学习率情况进行测试。随着学习率的增加，损失会慢慢变小，而后增加，而最佳的学习率就可以从其中损失最小的区域选择。有经验的工程人员常常根据自己的经验进行选择，比如0.1，0.01等。随着学习率的增加，模型也可能会从欠拟合过度到过拟合状态。

对于本实验来说，0.1为最优的学习率。

 

留出法不同比例对结果的影响和分析 （10分）

| 训练集所占比例           | 0.6    | 0.7    | 0.8    | 0.9    |
| ------------------------ | ------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.7927 | 0.7769 | 0.7957 | 0.8033 |

从上述实验中无法直观看出留出法的不同比例对于准确率的影响。留出法的训练集所占比对于模型准确率的影响是不稳定的。

k折交叉验证法不同k值对结果的影响和分析 （10分）

| k                        | 5      | 10     | 20     |
| ------------------------ | ------ | ------ | ------ |
| 1000次迭代后的模型准确率 | 0.9386 | 0.9514 | 0.9216 |

k值越大，偏差越小，方差越大，过拟合的可能性越大；k值越小，偏差越大，方差越小，模型欠拟合的可能性越大。总的来说，如果选取交叉验证法，需要选取合适的k值，才能使准确率更高。

从最终的结果来看，对于本实验来说，k=10为最优的k值。

**五、****实验总结及心得**

  从本次实验中，我学会了如何构建一个训练模型，并掌握了留出法和k折交叉验证法的原理，实现了对MNIST手写数字的识别。

在整个实验过程中，大家的模型构建可能都是大同小异的，但是从不同的训练参数中分析总结过程是很宝贵的。一个模型的好与坏很大程度上取决于所选择的参数是否合理，因此，不仅需要重视模型构建的方法，还需要体验调参过程、总结调参经验。

 